{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d0fd6287",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0fd6287",
        "outputId": "ff68d62b-836a-4583-dfc8-a6bf04272fb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Installing dependencies...\n",
            "üîë Authenticating with API Key...\n",
            "‚úÖ Success! Authenticated with Google AI Studio.\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Install & Auth (Google AI Studio Version)\n",
        "# ==============================================================================\n",
        "print(\"üì¶ Installing dependencies...\")\n",
        "# We switch from 'vertexai' to the simpler 'google-generativeai' library\n",
        "%pip install -q google-generativeai pydantic\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "try:\n",
        "    print(\"üîë Authenticating with API Key...\")\n",
        "    # 1. Fetch Key from Secrets\n",
        "    api_key = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "    # 2. Configure the library\n",
        "    genai.configure(api_key=api_key)\n",
        "\n",
        "    print(\"‚úÖ Success! Authenticated with Google AI Studio.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Auth Failed: {e}\")\n",
        "    print(\"Did you create a secret named 'GOOGLE_API_KEY' in the üîë tab?\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "XjbGJTjm_j-P",
        "outputId": "744a9796-f885-4dcd-d903-354fef4ead43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "XjbGJTjm_j-P",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adhd-assistant.ipynb  LICENSE\t   README.md\t     setup_config.py\n",
            "agents.py\t      __pycache__  requirements.txt  tools.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile agents.py\n",
        "\"\"\"Core agent definitions for the ADHD assistant architecture.\n",
        "\n",
        "This module defines three collaborating agents:\n",
        "1. ConversationManagerAgent: orchestrates the flow.\n",
        "2. TaskLogicAgent: decomposes user intent (Using Google AI Studio / Free Tier).\n",
        "3. ToolExecutionAgent: prepares and executes tool calls.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import os\n",
        "import json\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Any, Callable, Dict, List, Optional\n",
        "\n",
        "import google.generativeai as genai\n",
        "from tools import execute_tool\n",
        "\n",
        "# ---- Shared data models --------------------------------------------------------------------\n",
        "\n",
        "@dataclass\n",
        "class TaskItem:\n",
        "    description: str\n",
        "    status: str = \"pending\"\n",
        "    due: Optional[str] = None\n",
        "    priority: Optional[str] = None\n",
        "    conflicts: List[str] = field(default_factory=list)\n",
        "\n",
        "@dataclass\n",
        "class TaskPlan:\n",
        "    tasks: List[TaskItem]\n",
        "    encouragement: Optional[str] = None\n",
        "    conflicts: List[str] = field(default_factory=list)\n",
        "\n",
        "@dataclass\n",
        "class ToolAction:\n",
        "    kind: str\n",
        "    payload: Dict[str, Any]\n",
        "    description: str\n",
        "\n",
        "@dataclass\n",
        "class AgentTurn:\n",
        "    user_facing_message: str\n",
        "    tasks: List[TaskItem] = field(default_factory=list)\n",
        "    pending_actions: List[ToolAction] = field(default_factory=list)\n",
        "    requires_confirmation: bool = True\n",
        "\n",
        "# ---- Agents --------------------------------------------------------------------------------\n",
        "\n",
        "class TaskLogicAgent:\n",
        "    \"\"\"The engine: decomposes user intent using the Free Tier API.\"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str = \"gemini-1.5-pro-002\"): # <--- CHANGED to valid model name\n",
        "        self.model = genai.GenerativeModel(model_name)\n",
        "\n",
        "    def decompose_brain_dump(\n",
        "        self, user_text: str, context: Optional[Dict[str, Any]] = None\n",
        "    ) -> TaskPlan:\n",
        "        context = context or {}\n",
        "\n",
        "        prompt = self._construct_prompt(user_text, context)\n",
        "\n",
        "        try:\n",
        "            response = self.model.generate_content(\n",
        "                prompt,\n",
        "                generation_config=genai.GenerationConfig(\n",
        "                    response_mime_type=\"application/json\",\n",
        "                    temperature=0.2\n",
        "                )\n",
        "            )\n",
        "            plan = self._parse_model_response(response)\n",
        "        except Exception as e:\n",
        "            print(f\"Error calling model or parsing response: {e}\")\n",
        "            plan = TaskPlan(\n",
        "                tasks=[TaskItem(description=user_text)],\n",
        "                conflicts=[\"I had trouble decomposing that. Could you list them one by one?\"]\n",
        "            )\n",
        "\n",
        "        if context.get(\"encouragement_override\"):\n",
        "            plan.encouragement = context.get(\"encouragement_override\")\n",
        "\n",
        "        return plan\n",
        "\n",
        "    def _construct_prompt(self, user_text: str, context: Dict[str, Any]) -> str:\n",
        "        user_preferences = context.get(\"user_preferences\", \"No specific preferences.\")\n",
        "\n",
        "        return f\"\"\"\n",
        "        You are an expert Task Decomposer for ADHD assistants.\n",
        "        GOAL: Break down the user's text into atomic tasks.\n",
        "\n",
        "        OUTPUT SCHEMA (JSON):\n",
        "        {{\n",
        "            \"reasoning\": \"Step-by-step analysis string\",\n",
        "            \"tasks\": [\n",
        "                {{\n",
        "                    \"description\": \"Short task description\",\n",
        "                    \"due\": \"Due date or null\",\n",
        "                    \"priority\": \"high/medium/low\"\n",
        "                }}\n",
        "            ],\n",
        "            \"conflicts\": [\"List of potential conflicts strings\"],\n",
        "            \"encouragement\": \"Encouraging message string\"\n",
        "        }}\n",
        "\n",
        "        --- USER CONTEXT ---\n",
        "        {user_preferences}\n",
        "        --------------------\n",
        "\n",
        "        User's Brain Dump:\n",
        "        \"{user_text}\"\n",
        "        \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def _parse_model_response(response) -> TaskPlan:\n",
        "        try:\n",
        "            response_text = response.text\n",
        "            response_dict = json.loads(response_text)\n",
        "        except Exception:\n",
        "            return TaskPlan(tasks=[], conflicts=[\"Model response error\"])\n",
        "\n",
        "        tasks = [TaskItem(**task_data) for task_data in response_dict.get(\"tasks\", [])]\n",
        "        return TaskPlan(\n",
        "            tasks=tasks,\n",
        "            conflicts=response_dict.get(\"conflicts\", []),\n",
        "            encouragement=response_dict.get(\"encouragement\", \"You got this!\"),\n",
        "        )\n",
        "\n",
        "\n",
        "class ToolExecutionAgent:\n",
        "    \"\"\"The hands: schedules tasks, sets reminders.\"\"\"\n",
        "\n",
        "    def propose_actions(self, tasks: List[TaskItem]) -> List[ToolAction]:\n",
        "        actions: List[ToolAction] = []\n",
        "        for task in tasks:\n",
        "            if task.due:\n",
        "                actions.append(\n",
        "                    ToolAction(\n",
        "                        kind=\"schedule_event\",\n",
        "                        payload={\"task_description\": task.description, \"due_date\": task.due, \"priority\": task.priority or 'normal'},\n",
        "                        description=f\"‚úÖ Schedule '{task.description}' for {task.due}\",\n",
        "                    )\n",
        "                )\n",
        "            else:\n",
        "                actions.append(\n",
        "                    ToolAction(\n",
        "                        kind=\"set_reminder\",\n",
        "                        payload={\"task_description\": task.description, \"remind_at\": '1 hour from now'},\n",
        "                        description=f\"üîî Set reminder for '{task.description}'\",\n",
        "                    )\n",
        "                )\n",
        "        return actions\n",
        "\n",
        "    def execute_actions(self, actions: List[ToolAction]) -> List[Any]:\n",
        "        results: List[Any] = []\n",
        "        for action in actions:\n",
        "            try:\n",
        "                result = execute_tool(action.kind, action.payload)\n",
        "                results.append(result)\n",
        "            except Exception as e:\n",
        "                print(f\"Error executing action '{action.kind}': {e}\")\n",
        "                results.append({\"status\": \"error\", \"details\": str(e)})\n",
        "        return results\n",
        "\n",
        "\n",
        "class ConversationManagerAgent:\n",
        "    \"\"\"The face/orchestrator.\"\"\"\n",
        "\n",
        "    def __init__(self, task_agent: TaskLogicAgent, tool_agent: ToolExecutionAgent) -> None:\n",
        "        self.task_agent = task_agent\n",
        "        self.tool_agent = tool_agent\n",
        "\n",
        "    def handle_user_message(\n",
        "        self,\n",
        "        user_text: str,\n",
        "        user_id: str = \"default_user\",\n",
        "        auto_confirm: bool = False,\n",
        "    ) -> AgentTurn:\n",
        "\n",
        "        context_action = ToolAction(\n",
        "            kind=\"get_user_context\",\n",
        "            payload={\"user_id\": user_id},\n",
        "            description=\"Fetching user context.\",\n",
        "        )\n",
        "        context_result = self.tool_agent.execute_actions([context_action])\n",
        "        context = context_result[0].get(\"context\", {})\n",
        "\n",
        "        plan = self.task_agent.decompose_brain_dump(user_text=user_text, context=context)\n",
        "\n",
        "        pending_actions = self.tool_agent.propose_actions(plan.tasks)\n",
        "        requires_confirmation = not auto_confirm\n",
        "\n",
        "        if auto_confirm:\n",
        "            self.tool_agent.execute_actions(pending_actions)\n",
        "\n",
        "        message_parts: List[str] = []\n",
        "        if plan.encouragement:\n",
        "            message_parts.append(plan.encouragement)\n",
        "\n",
        "        if plan.tasks:\n",
        "            message_parts.append(\"\\nHere's what I've broken down for you:\")\n",
        "            for idx, task in enumerate(plan.tasks, start=1):\n",
        "                task_details = [f\"{idx}. {task.description}\"]\n",
        "                if task.due:\n",
        "                    task_details.append(f\" (Due: {task.due})\")\n",
        "                message_parts.append(\"\".join(task_details))\n",
        "\n",
        "        if pending_actions and requires_confirmation:\n",
        "            message_parts.append(\"\\nI'll set these up for you:\")\n",
        "            for action in pending_actions:\n",
        "                message_parts.append(f\"- {action.description}\")\n",
        "            message_parts.append(\"\\nSound good?\")\n",
        "        elif not plan.tasks:\n",
        "            message_parts.append(\"I couldn't find any specific tasks to list. Could you rephrase?\")\n",
        "\n",
        "        return AgentTurn(\n",
        "            user_facing_message=\"\\n\".join(message_parts),\n",
        "            tasks=plan.tasks,\n",
        "            pending_actions=pending_actions,\n",
        "            requires_confirmation=requires_confirmation,\n",
        "        )"
      ],
      "metadata": {
        "id": "2mwLSTgtD7IW",
        "outputId": "2be22173-a886-4736-da66-38c94ab22c3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "2mwLSTgtD7IW",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting agents.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 1. Navigate into the project folder\n",
        "if os.path.exists(\"adhd-assistant-capstone\"):\n",
        "    %cd adhd-assistant-capstone\n",
        "    print(\"üìÇ Navigated to project folder.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Folder not found. Cloning now...\")\n",
        "    !git clone https://github.com/viveksahukar/adhd-assistant-capstone.git\n",
        "    %cd adhd-assistant-capstone\n",
        "\n",
        "# 2. Re-create the missing setup_config.py file\n",
        "# (We do this to ensure it exists even if it wasn't pushed to GitHub)\n",
        "with open(\"setup_config.py\", \"w\") as f:\n",
        "    f.write('''\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from google.oauth2 import service_account\n",
        "from google.cloud import aiplatform as vertexai\n",
        "import json\n",
        "\n",
        "def initialize_environment(project_id: str):\n",
        "    print(\"--- üöÄ Starting Cloud-Native Authentication ---\")\n",
        "\n",
        "    try:\n",
        "        # 1. Get the JSON string from Colab Secrets\n",
        "        # Make sure the name inside get() matches your Secret name exactly!\n",
        "        key_json = userdata.get('GCP_CREDENTIALS')\n",
        "\n",
        "        # 2. Convert that string into a format Google's auth library understands\n",
        "        key_info = json.loads(key_json)\n",
        "        credentials = service_account.Credentials.from_service_account_info(key_info)\n",
        "\n",
        "        # 3. Initialize Vertex AI\n",
        "        os.environ[\"GCP_PROJECT_ID\"] = project_id\n",
        "        vertexai.init(\n",
        "            project=project_id,\n",
        "            location=\"us-central1\",\n",
        "            credentials=credentials\n",
        "        )\n",
        "\n",
        "        print(\"‚úÖ Success! Authenticated using Colab Secrets.\")\n",
        "        print(f\"Service Account: {credentials.service_account_email}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Auth Failed: {e}\")\n",
        "        print(\"Check: Did you create a secret named 'GCP_CREDENTIALS' in the üîë tab?\")\n",
        "\n",
        "    return None, os, vertexai\n",
        "''')\n",
        "print(\"‚úÖ setup_config.py created/verified.\")\n",
        "\n",
        "# 3. Install Dependencies\n",
        "print(\"üì¶ Installing dependencies...\")\n",
        "%pip install -q -r requirements.txt\n",
        "\n",
        "# 4. Run your Initialization\n",
        "print(\"üöÄ Initializing Project...\")\n",
        "from setup_config import initialize_environment\n",
        "\n",
        "# Replace with your project ID\n",
        "PROJECT_ID = \"adhd-assistant-capstone\"\n",
        "auth, os, vertexai = initialize_environment(PROJECT_ID)"
      ],
      "metadata": {
        "id": "voTKDmVUAUjg",
        "outputId": "4d8274dc-0134-4d50-e9ba-5e2fc0b7cc8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "voTKDmVUAUjg",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è Folder not found. Cloning now...\n",
            "Cloning into 'adhd-assistant-capstone'...\n",
            "remote: Enumerating objects: 70, done.\u001b[K\n",
            "remote: Counting objects: 100% (70/70), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 70 (delta 37), reused 37 (delta 14), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (70/70), 34.18 KiB | 972.00 KiB/s, done.\n",
            "Resolving deltas: 100% (37/37), done.\n",
            "/content/adhd-assistant-capstone\n",
            "‚úÖ setup_config.py created/verified.\n",
            "üì¶ Installing dependencies...\n",
            "üöÄ Initializing Project...\n",
            "--- üöÄ Starting Cloud-Native Authentication ---\n",
            "‚úÖ Success! Authenticated using Colab Secrets.\n",
            "Service Account: colab-runner@adhd-assistant-capstone.iam.gserviceaccount.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1015ad84",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1015ad84",
        "outputId": "f45781ac-1fdf-4abc-cce3-2c6b176dada9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- üöÄ Starting Cloud-Native Authentication ---\n",
            "‚úÖ Success! Authenticated using Colab Secrets.\n",
            "Service Account: colab-runner@adhd-assistant-capstone.iam.gserviceaccount.com\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Project Initialization\n",
        "# =================================================================\n",
        "from setup_config import initialize_environment\n",
        "\n",
        "# Your specific Project ID\n",
        "PROJECT_ID = \"adhd-assistant-capstone\"\n",
        "\n",
        "# Initialize Vertex AI and auth\n",
        "# This returns the modules if you need to inspect them, but mainly sets up the global state.\n",
        "auth, os, vertexai = initialize_environment(PROJECT_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "263143c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "263143c8",
        "outputId": "9a8a6d16-fb0c-4293-c251-b3b583b15e1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Successfully imported Agent classes.\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Import Agent Modules\n",
        "# =================================================================\n",
        "try:\n",
        "    from agents import ConversationManagerAgent, TaskLogicAgent, ToolExecutionAgent\n",
        "    print(\"‚úÖ Successfully imported Agent classes.\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Error importing agents: {e}\")\n",
        "    print(\"Make sure agents.py and tools.py are in the current folder.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0a3d7f06",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a3d7f06",
        "outputId": "84a20021-dcd4-443e-83df-a3bfec848e8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Agent System Online. Ready for user input.\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Create Agent Instances\n",
        "# =================================================================\n",
        "# 1. Create the Specialist Agents\n",
        "# Note: TaskLogicAgent now defaults to 'gemini-2.5-pro' per our refinement\n",
        "task_agent = TaskLogicAgent()\n",
        "tool_agent = ToolExecutionAgent()\n",
        "\n",
        "# 2. Create the Supervisor (Conversation Manager)\n",
        "# This injects the specialists into the coordinator\n",
        "manager = ConversationManagerAgent(task_agent=task_agent, tool_agent=tool_agent)\n",
        "\n",
        "print(\"‚úÖ Agent System Online. Ready for user input.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "83ad8334",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "83ad8334",
        "outputId": "ce5a83e0-fb46-4950-d685-4a75bfdbe5bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üë§ USER SAYS:\n",
            "I have a big presentation on Friday morning at 10 AM. I need to call the doctor sometime next week to make an appointment, and I also have to remember to buy eggs and bread today.\n",
            "\n",
            "------------------------------------------------------------\n",
            "--- TOOL: Fetching context for user: 'notebook_test_user_01' ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:404 POST /v1beta/models/gemini-1.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 733.65ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error calling model or parsing response: 404 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: models/gemini-1.5-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
            "ü§ñ AGENT RESPONDS:\n",
            "\n",
            "Here's what I've broken down for you:\n",
            "1. I have a big presentation on Friday morning at 10 AM. I need to call the doctor sometime next week to make an appointment, and I also have to remember to buy eggs and bread today.\n",
            "\n",
            "I'll set these up for you:\n",
            "- üîî Set reminder for 'I have a big presentation on Friday morning at 10 AM. I need to call the doctor sometime next week to make an appointment, and I also have to remember to buy eggs and bread today.'\n",
            "\n",
            "Sound good?\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: Simulate User Interaction\n",
        "# =================================================================\n",
        "\n",
        "# 1. Define the User's \"Brain Dump\"\n",
        "user_input = (\n",
        "    \"I have a big presentation on Friday morning at 10 AM. \"\n",
        "    \"I need to call the doctor sometime next week to make an appointment, \"\n",
        "    \"and I also have to remember to buy eggs and bread today.\"\n",
        ")\n",
        "\n",
        "print(f\"üë§ USER SAYS:\\n{user_input}\\n\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# 2. Handle the message (with auto_confirm=False to test HITL)\n",
        "# This mimics the \"Think\" step where the agent plans but waits for approval\n",
        "agent_turn = manager.handle_user_message(\n",
        "    user_text=user_input,\n",
        "    user_id=\"notebook_test_user_01\",\n",
        "    auto_confirm=False\n",
        ")\n",
        "\n",
        "# 3. Display the Agent's proposed response\n",
        "print(f\"ü§ñ AGENT RESPONDS:\\n{agent_turn.user_facing_message}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4da0e5dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4da0e5dc",
        "outputId": "2eb48dc2-0e5c-494d-ce47-3321252edebc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ USER ACTION: Confirming plan...\n",
            "\n",
            "--- TOOL: Setting reminder: 'I have a big presentation on Friday morning at 10 AM. I need to call the doctor sometime next week to make an appointment, and I also have to remember to buy eggs and bread today.' at 1 hour from now ---\n",
            "--- üõ†Ô∏è Tool Execution Results ---\n",
            "[SUCCESS] Reminder for 'I have a big presentation on Friday morning at 10 AM. I need to call the doctor sometime next week to make an appointment, and I also have to remember to buy eggs and bread today.' set for 1 hour from now.\n"
          ]
        }
      ],
      "source": [
        "# Cell 6: User Confirmation & Tool Execution\n",
        "# =================================================================\n",
        "\n",
        "if agent_turn.requires_confirmation:\n",
        "    print(\"‚úÖ USER ACTION: Confirming plan...\\n\")\n",
        "\n",
        "    # Execute the pending actions using the Tool Execution Agent\n",
        "    # This mimics the \"Act\" step\n",
        "    results = tool_agent.execute_actions(agent_turn.pending_actions)\n",
        "\n",
        "    print(\"--- üõ†Ô∏è Tool Execution Results ---\")\n",
        "    for res in results:\n",
        "        # Check for success/failure in the tool output\n",
        "        status = res.get(\"status\", \"unknown\")\n",
        "        details = res.get(\"details\", str(res))\n",
        "        print(f\"[{status.upper()}] {details}\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è No actions required confirmation.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}